{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Load Docs into OpenSearch Serverless Vector Database \n",
    "\n",
    "- SageMaker Notebook Kernel: `conda_python3`\n",
    "- SageMaker Notebook Instance Type: ml.m5d.large | ml.t3.large\n",
    "\n",
    "In this notebook, you will load previously extracted, split, and embedded texts from the [Amazon Bedrock](https://aws.amazon.com/bedrock/) user guide into [Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-vector-search.html) database. OpenSearch is a fully open-source search and analytics engine for use cases such as log analytics, real-time application monitoring, and clickstream analysis. In this notebook we use will a new feature (in preview as of November 2023) named Vector Search. The vector search collection type in OpenSearch Serverless provides a similarity search capability that is scalable and high performing. It makes it easy for you to build modern machine learning (ML) augmented search experiences and generative artificial intelligence (AI) applications without having to manage the underlying vector database infrastructure.\n",
    "\n",
    "## Runtime \n",
    "\n",
    "This notebook takes approximately 10 minutes to run.\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Prerequisites](#prerequisites)\n",
    "1. [Setup](#setup)\n",
    "1. [Download data](#download-data)\n",
    "1. [Get OpenSearch Serverless collection name](#get-opensearch-serverless-collection-name)\n",
    "1. [Update the OpenSearch access policy](#update-the-opensearch-access-policy-with-the-notebook-assumed-role)\n",
    "1. [Create the OpenSearch runtime client](#create-the-opensearch-runtime-client)\n",
    "1. [Patch the OpenSearch client creation in LangChain](#patch-the-opensearch-client-creation-in-langchain)\n",
    "1. [Load embeddings into OpenSearch](#load-embeddings-into-opensearch)\n",
    "1. [Similarity Search](#similarity-search)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "`amazon.titan-embed-text-v1` enabled in the Amazon Bedrock console in `us-west-2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by installing and importing the required packages for this notebook. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Note:</b> Verify that the notebook kernel is `conda_python3`. Also, if you run into an issue where a module can't be imported after installation, restart the notebook kernel, then rerun the import notebook cell.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain==0.0.317 --quiet\n",
    "%pip install opensearch-py==2.3.2 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import boto3\n",
    "import langchain.vectorstores.opensearch_vector_search as ovs\n",
    "\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection,AWSV4SignerAuth, helpers\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import OpenSearchVectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Next, you will initialize the Amazon Bedrock boto3 client and the Amazon OpenSearch Serverless boto3 client. \n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_session = boto3.Session()\n",
    "aoss_client = boto3_session.client(\"opensearchserverless\")\n",
    "region = boto3_session.region_name\n",
    "\n",
    "bedrock_client = boto3_session.client(\"bedrock-runtime\")\n",
    "embeddings_model_id = \"amazon.titan-embed-text-v1\"\n",
    "\n",
    "# Create the data directory\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "bedrock_embeddings = BedrockEmbeddings(\n",
    "    client=bedrock_client, model_id=embeddings_model_id\n",
    ")\n",
    "\n",
    "print(f\"boto3 region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "\n",
    "To save some time, we extracted all of the content on the [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide) site, split the data into chunks, and generated the embeddings. Let's download the file from S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_bucket = os.getenv(\"ASSETS_BUCKET_NAME\")\n",
    "s3_data_prefix = os.getenv(\"ASSETS_BUCKET_PREFIX\")\n",
    "s3_data_uri = f\"s3://{s3_data_bucket}/{s3_data_prefix}data/bedrock_user_guide_embeddings.pkl\"\n",
    "!aws s3 cp {s3_data_uri} ./data/bedrock_user_guide_embeddings.pkl --region {region}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Open the the file and print details about the contents. The file contains a dictionary with three arrays; one for the document text, one for the metadata about the document, and one for the embeddings. This data structure makes it easy to load the documents into OpenSearch.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"data\", \"bedrock_user_guide_embeddings.pkl\"), \"rb\") as f:\n",
    "   bedrock_user_guide_embeddings = pickle.load(f)\n",
    "\n",
    "stats = {key: len(bedrock_user_guide_embeddings[key]) for key in bedrock_user_guide_embeddings}\n",
    "\n",
    "print(json.dumps(stats, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OpenSearch Serverless collection name\n",
    "\n",
    "The OpenSearch collection has already been created for you. Let's query the collections and print the collection name and id. There should only be one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_collections_response = aoss_client.list_collections()\n",
    "collections = list_collections_response\n",
    "collection = collections.get(\"collectionSummaries\")[0]\n",
    "collection_id = collection.get(\"id\")\n",
    "collection_name = collection.get(\"name\")\n",
    "\n",
    "print(f\"Collection Id: {collection_id}\")\n",
    "print(f\"Collection Name: {collection_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the OpenSearch access policy with the notebook assumed role\n",
    "\n",
    "The OpenSearch encryption, network, and access policies were created with the collection for you, but the assumed role of the SageMaker notebook hasn't been added to the access policy yet. We need to update the principals with the notebooks assumed role to be able to access the runtime api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_access_policy(policy_name):\n",
    "    policy_type = \"data\"\n",
    "    policy_response = aoss_client.get_access_policy(name=policy_name, type=policy_type)\n",
    "    access_policy_detail = policy_response.get(\"accessPolicyDetail\")\n",
    "    policy = access_policy_detail.get(\"policy\")\n",
    "    policy_version = access_policy_detail.get(\"policyVersion\")\n",
    "    policy_principals = policy[0].get(\"Principal\")\n",
    "    assumed_role_arn = boto3.client(\"sts\").get_caller_identity().get(\"Arn\")\n",
    "    update_needed = False\n",
    "    if assumed_role_arn not in policy_principals:\n",
    "        policy_principals.append(assumed_role_arn)\n",
    "        update_needed = True\n",
    "    if update_needed:\n",
    "        print(\"Updating the access policy with the notebook assumed role\")\n",
    "        response = aoss_client.update_access_policy(\n",
    "            name=policy_name, policy=json.dumps(policy), policyVersion=policy_version, type=policy_type\n",
    "        )\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"Notebook assumed role already exists in the policy, skipping update\")\n",
    "\n",
    "\n",
    "update_access_policy(f\"{collection_name}-access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the OpenSearch runtime client\n",
    "\n",
    "Create the `OpenSearch` runtime client. The `AWSV4SignerAuth` class handles signing the requests with [AWS Signature V4](https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html) allowing us to use AWS IAM role credentials when invoking the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = \"aoss\"\n",
    "host = f\"{collection_id}.{region}.aoss.amazonaws.com\"\n",
    "\n",
    "credentials = boto3_session.get_credentials()\n",
    "http_auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "aoss_runtime_client = OpenSearch(\n",
    "    hosts=[{\"host\": host, \"port\": 443}],\n",
    "    http_auth=http_auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300,\n",
    "    pool_maxsize=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch the OpenSearch client creation in LangChain\n",
    "\n",
    "The `OpenSearchVectorSearch` class from LangChain doesn't allow you to pass the OpenSearch client you just created. Since we want to use AWS IAM role based credentials, you will patch the `_get_opensearch_client` method to return our pre-configured client when executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opensearch_client(opensearch_url: str, **kwargs):\n",
    "    return aoss_runtime_client\n",
    "\n",
    "ovs._get_opensearch_client = get_opensearch_client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load embeddings into OpenSearch \n",
    "\n",
    "The `OpenSearchVectorSearch` class from LangChain does a lot of the heavy lifting for us. The static `from_embeddings` method will create the index and upload the texts, metadata, and embeddings to the database and then return an instance of itself that we can use for similarity searching. One of the parameters to the class is the `BedrockEmbeddings` we used in an earlier notebook. The embeddings model is used when loading new texts as well as when searching for documents based on text. If you want to learn more about the class see [OpenSearchVectorSearch](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.opensearch_vector_search.OpenSearchVectorSearch.html). \n",
    "\n",
    "There are some restrictions of which engines and similarity algorithms you can use when using the vector search component of OpenSearch Serverless. To learn more see [OpenSearch Developer Guide](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-vector-search.html). For this workshop you will create the index using cosine similarity with the `nmslib` engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"bedrock-docs\"\n",
    "\n",
    "db = OpenSearchVectorSearch.from_embeddings(\n",
    "    opensearch_url=host,\n",
    "    http_auth=http_auth,\n",
    "    index_name=index_name,\n",
    "    engine=\"nmslib\",\n",
    "    space_type=\"cosinesimil\",\n",
    "    embedding=bedrock_embeddings,\n",
    "    **bedrock_user_guide_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Query the index and take a look at the contents.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = aoss_runtime_client.indices.get(index_name)\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity search\n",
    "\n",
    "Run a couple of queries and review the results. The `similarity_search_with_score` returns a number of documents defined by `k`, which is the second parameter of the function, with the similarity scores. We can use the scores to eliminate results that return with low similarity.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Note:</b> It takes a minute or two after uploading the texts to OpenSearch for them to be indexed and available for query. If you run the cell below and it returns no results, wait a minute, then run the cell again.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search_with_score(\"What is Amazon Bedrock?\", 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search_with_score(\"What large language models are available on bedrock?\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Try a query for completely unrelated input. What do you notice?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search_with_score(\"Who was the main actor in Jurrasic Park?\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Try your own queries below about Amazon Bedrock and see if the results match your understanding. If you are unfamiliar with Bedrock, navigate to the [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide) and peek around.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search_with_score(\"<question-here>\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook complete\n",
    "\n",
    "Now that we have all the data loaded into OpenSearch Serverless, move to the next notebook to learn how to tie the model and data together using LangChain.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
